{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#垃圾邮件的内容\n",
    "posting_list = [\n",
    "    ['my', 'dog', 'has', 'flea', 'problem', 'help', 'please'],\n",
    "    ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "    ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
    "    ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
    "    ['mr', 'licks', 'ate', 'ny', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "    ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']\n",
    "    ]\n",
    "#是否是垃圾邮件的标签\n",
    "labels = [0, 1, 0, 1, 0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVocabList(dataSet):\n",
    "    '''\n",
    "    创建所有文档中出现的不重复词汇列表\n",
    "    Args:\n",
    "        dataSet: 所有文档\n",
    "    Return:\n",
    "        包含所有文档的不重复词列表，即词汇表\n",
    "    '''\n",
    "    vocabSet = set([])\n",
    "    # 创建两个集合的并集\n",
    "    for document in dataSet:\n",
    "        vocabSet = vocabSet | set(document)\n",
    "    return list(vocabSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 词袋模型(bag-of-words model):词在文档中出现的次数\n",
    "def bagOfWords2Vec(vocabList, inputSet):\n",
    "    '''\n",
    "    依据词汇表，将输入文本转化成词袋模型词向量\n",
    "    Args:\n",
    "        vocabList: 词汇表\n",
    "        inputSet: 当前输入文档\n",
    "    Return:\n",
    "        returnVec: 转换成词向量的文档\n",
    "    例子：\n",
    "        vocabList = ['I', 'love', 'python', 'and', 'machine', 'learning']\n",
    "        inputset = ['python', 'machine', 'learning', 'python', 'machine']\n",
    "        returnVec = [0, 0, 2, 0, 2, 1]\n",
    "        长度与词汇表一样长，出现了的位置为1，未出现为0，如果词汇表中无该单词则print\n",
    "    '''\n",
    "    returnVec = [0] * len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] += 1\n",
    "        else:\n",
    "            print(\"the word: %s is not in my vocabulary!\" % word)\n",
    "        return returnVec    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, trainMatrix, trainCategory):\n",
    "    '''\n",
    "    朴素贝叶斯分类器训练函数，求：p(Ci),基于词汇表的p(w|Ci)\n",
    "    Args:\n",
    "        trainMatrix : 训练矩阵，即向量化表示后的文档（词条集合）\n",
    "        trainCategory : 文档中每个词条的列表标注\n",
    "    Return:\n",
    "        p0Vect : 属于0类别的概率向量(p(w1|C0),p(w2|C0),...,p(wn|C0))\n",
    "        p1Vect : 属于1类别的概率向量(p(w1|C1),p(w2|C1),...,p(wn|C1))\n",
    "        pAbusive : 属于1类别文档的概率\n",
    "    '''\n",
    "    numTrainDocs = len(trainMatrix)\n",
    "    # 长度为词汇表长度\n",
    "    numWords = len(trainMatrix[0])\n",
    "    # p(ci)\n",
    "    self.pAbusive = sum(trainCategory) / float(numTrainDocs)\n",
    "    # 由于后期要计算p(w|Ci)=p(w1|Ci)*p(w2|Ci)*...*p(wn|Ci)，若wj未出现，则p(wj|Ci)=0,因此p(w|Ci)=0，这样显然是不对的\n",
    "    # 故在初始化时，将所有词的出现数初始化为1，分母即出现词条总数初始化为2\n",
    "    p0Num = np.ones(numWords)\n",
    "    p1Num = np.ones(numWords)\n",
    "    p0Denom = 2.0\n",
    "    p1Denom = 2.0\n",
    "    for i in range(numTrainDocs):\n",
    "        if trainCategory[i] == 1:\n",
    "            p1Num += trainMatrix[i]\n",
    "            p1Denom += sum(trainMatrix[i])\n",
    "        else:\n",
    "            p0Num += trainMatrix[i]\n",
    "            p0Denom += sum(trainMatrix[i])\n",
    "    # p(wi | c1)\n",
    "    # 为了避免下溢出（当所有的p都很小时，再相乘会得到0.0，使用log则会避免得到0.0）\n",
    "    self.p1Vect = np.log(p1Num / p1Denom)\n",
    "    # p(wi | c2)\n",
    "    self.p0Vect = np.log(p0Num / p0Denom)\n",
    "    return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, testX):\n",
    "    '''\n",
    "    朴素贝叶斯分类器\n",
    "    Args:\n",
    "        testX : 待分类的文档向量（已转换成array）\n",
    "        p0Vect : p(w|C0)\n",
    "        p1Vect : p(w|C1)\n",
    "        pAbusive : p(C1)\n",
    "    Return:\n",
    "        1 : 为侮辱性文档 (基于当前文档的p(w|C1)*p(C1)=log(基于当前文档的p(w|C1))+log(p(C1)))\n",
    "        0 : 非侮辱性文档 (基于当前文档的p(w|C0)*p(C0)=log(基于当前文档的p(w|C0))+log(p(C0)))\n",
    "    '''\n",
    "\n",
    "    p1 = np.sum(testX * self.p1Vect) + np.log(self.pAbusive)\n",
    "    p0 = np.sum(testX * self.p0Vect) + np.log(1 - self.pAbusive)\n",
    "    if p1 > p0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
